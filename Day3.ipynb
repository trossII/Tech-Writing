{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "March 19 2020\n",
    "\n",
    "Today we learned about Random Forest Models. Random Forest models are an expansion on decision trees where you can use estimation of the masses of many trees to get rid of high varience and of over fitting of one tree by itself. To do this you need to use different samples of your training dataset with replacement through bootstrapping and adjustment of your hyper parameters. Below is an example of and awesome took called GridSearchCV that uses the hyperparameters you select to find what features best fit the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of parameter you want the model to try\n",
    "param_grid = {\n",
    "    'max_features': ['sqrt', 'log2', 0.1],\n",
    "    'criterion': ['mse', 'mae']\n",
    "}\n",
    "\n",
    "# Inserting those parameters into the GridSearchCV\n",
    "gs = GridSearchCV(estimator=et, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit your data into gridsearch\n",
    "gs.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
