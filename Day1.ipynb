{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "March 17 2020\n",
    "\n",
    "Today we learned about K-Nearest Neighbors. What I found interesting about KNN was that there are 3 general ways to find the distance but the first two (Manhattan and Euclidean) are the same as Minkowski (shown below) if you just use one or two for the value of C. The second thing that suprised me about the these different metrics for distance is that when we actually used them with sklearn they actually gave us various results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large d(x, y) = \\left(\\sum_{i=1}^{n}|x_i - y_i|^c\\right)^\\frac{1}{c}$$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
